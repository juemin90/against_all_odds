{
  "_args": [
    [
      {
        "raw": "crawler",
        "scope": null,
        "escapedName": "crawler",
        "name": "crawler",
        "rawSpec": "",
        "spec": "latest",
        "type": "tag"
      },
      "/Users/lujuemin/Documents/juemin/study/odds"
    ]
  ],
  "_from": "crawler@latest",
  "_hasShrinkwrap": false,
  "_id": "crawler@1.2.1",
  "_inCache": true,
  "_location": "/crawler",
  "_nodeVersion": "10.14.0",
  "_npmOperationalInternal": {
    "host": "s3://npm-registry-packages",
    "tmp": "tmp/crawler_1.2.1_1555405847201_0.6610304112426113"
  },
  "_npmUser": {
    "name": "mike442144",
    "email": "mike442144@hotmail.com"
  },
  "_npmVersion": "6.9.0",
  "_phantomChildren": {
    "css-select": "1.2.0",
    "dom-serializer": "0.1.1",
    "entities": "1.1.2",
    "htmlparser2": "3.10.1",
    "lodash.assignin": "4.2.0",
    "lodash.bind": "4.2.1",
    "lodash.defaults": "4.2.0",
    "lodash.filter": "4.6.0",
    "lodash.flatten": "4.4.0",
    "lodash.foreach": "4.5.0",
    "lodash.map": "4.6.0",
    "lodash.merge": "4.6.2",
    "lodash.pick": "4.4.0",
    "lodash.reduce": "4.6.0",
    "lodash.reject": "4.6.0",
    "lodash.some": "4.6.0"
  },
  "_requested": {
    "raw": "crawler",
    "scope": null,
    "escapedName": "crawler",
    "name": "crawler",
    "rawSpec": "",
    "spec": "latest",
    "type": "tag"
  },
  "_requiredBy": [
    "#USER"
  ],
  "_resolved": "https://registry.npmjs.org/crawler/-/crawler-1.2.1.tgz",
  "_shasum": "396d3fc0e2c227463dcb165bead5c5dd5cf3062a",
  "_shrinkwrap": null,
  "_spec": "crawler",
  "_where": "/Users/lujuemin/Documents/juemin/study/odds",
  "bugs": {
    "url": "https://github.com/bda-research/node-crawler/issues"
  },
  "dependencies": {
    "bottleneckp": "~1.1.3",
    "cheerio": "^0.22.0",
    "iconv-lite": "^0.4.8",
    "lodash": "^4.17.10",
    "request": "~2.88.0",
    "seenreq": "^3.0.0",
    "type-is": "^1.6.14"
  },
  "description": "Crawler is a web spider written with Nodejs. It gives you the full power of jQuery on the server to parse a big number of pages as they are downloaded, asynchronously",
  "devDependencies": {
    "chai": "^4.2.0",
    "coveralls": "^3.0.2",
    "eslint": "^5.0.0",
    "jsdom": "^9.6.0",
    "mocha": "^6.1.0",
    "mocha-testdata": "^1.2.0",
    "nock": "^10.0.6",
    "nyc": "^13.1.0",
    "sinon": "^7.0.0",
    "whacko": "^0.19.1"
  },
  "directories": {
    "test": "tests"
  },
  "dist": {
    "integrity": "sha512-5hpo+iqAwIl0TXs+c3u5V1gQd4NqsiFDF0QiGZCE/OolLiY1QZA32AaDqAPTTmmxErwYJEoi6lN1j8mO4/WE+A==",
    "shasum": "396d3fc0e2c227463dcb165bead5c5dd5cf3062a",
    "tarball": "https://registry.npmjs.org/crawler/-/crawler-1.2.1.tgz",
    "fileCount": 41,
    "unpackedSize": 850604,
    "npm-signature": "-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v3.0.4\r\nComment: https://openpgpjs.org\r\n\r\nwsFcBAEBCAAQBQJctZwYCRA9TVsSAnZWagAAZ0QP/ivYdccO6ZKTtx0RxpU0\nDsi0s+gaalerLtkuaSwOOWeuvbZA2D7ouN/LCMQDcJt8wuxdl19WDmiopxJ7\nILeBjcJ/kQU6mYapc2AKIQQdOdVAKN+EbLeDn1KzVwBPhsvliHd2S6RwmAVo\nobLMD7UjaGv9hs48EnrdsuJ9ZMl60w6itOjMczTgFamdZ6nKoljGXHAYc4P5\nG9GH/B0D/NSOWJswW+UWoHhGI98zhOtIeHpxb3ACu5yO7gFdZeImiyuDvwsZ\n8MczuEud4HQwXfu9lRIJyU9tnXAooVSOP8wtllKlgcvrs35gvvQaoPt3315W\nSfG/Zs0aqd8yXQpmSpGPKJrrsAWRuMSHr7UotFh5U8EjyR9+J2YXOuYx8ZRf\nYSjzhcyPuVFiehpXs/901AE4HQ9+7IN2Bvo/S8rR1WNmVfj0qR7hd5sHnIlh\nWewMI+xGUeRGNQ6OuN/sCX2MyGQasrSTG+VdPHZgHAe+4dTUBKmH4cdtIz4U\ne3wxDMLXiVPyCqCd2srAHnEcwRKNwUGmb/NN/SQSvfgyo4FfmCEQLAaEL2SY\nqP/jsLGQlVAoe7ILdYQp9KlCy5GgWuVrdyIYlQEW/gwRLAAO/Ohua6uK57Rx\nL/hvZbUH2L0Xi6AYEyNxX0F29bwUcFnMTUxOP/Z9xoDPZ+2/NXoRZ0h4gmyJ\nsn0H\r\n=4kNV\r\n-----END PGP SIGNATURE-----\r\n"
  },
  "engine-strict": {
    "node": ">=4.0.0"
  },
  "gitHead": "34bcfb45d303e332d564a4a56c843868c52a6141",
  "homepage": "https://github.com/bda-research/node-crawler",
  "keywords": [
    "dom",
    "javascript",
    "crawling",
    "spider",
    "scraper",
    "scraping",
    "jquery",
    "crawler",
    "nodejs"
  ],
  "licenses": [
    {
      "type": "MIT",
      "url": "http://github.com/bda-research/node-crawler/blob/master/LICENSE.txt"
    }
  ],
  "main": "./lib/crawler.js",
  "maintainers": [
    {
      "name": "darrenqc",
      "email": "darrenqc823@gmail.com"
    },
    {
      "name": "mike442144",
      "email": "mike442144@hotmail.com"
    },
    {
      "name": "paulvalla",
      "email": "bonjour@pol.ninja"
    },
    {
      "name": "sylvinus",
      "email": "sylvain@sylvainzimmer.com"
    }
  ],
  "name": "crawler",
  "optionalDependencies": {},
  "readme": "ERROR: No README data found!",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/bda-research/node-crawler.git"
  },
  "scripts": {
    "cover": "nyc --reporter=lcovonly --reporter=text --reporter=text-summary mocha --timeout=15000 --reporter spec tests/*.test.js",
    "hint": "eslint ./lib/*.js ./tests/*.js",
    "test": "mocha --timeout=15000 tests/*.test.js"
  },
  "version": "1.2.1"
}
